{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "from bs4 import *\n",
    "import requests\n",
    "\n",
    "# Given URL\n",
    "url = \"https://id.wikipedia.org/wiki/Daftar_tokoh_agama_Indonesia\"\n",
    "\n",
    "# Fetch URL Content\n",
    "r = requests.get(url)\n",
    "\n",
    "# Get body content\n",
    "soup = BeautifulSoup(r.text, \"html.parser\").select(\"body\")[0]\n",
    "\n",
    "# Initialize variable\n",
    "paragraphs = []\n",
    "images = []\n",
    "link = []\n",
    "heading = []\n",
    "remaining_content = []\n",
    "\n",
    "# Iterate through all tags\n",
    "for tag in soup.find_all():\n",
    "    # Check each tag name\n",
    "    # For Paragraph use p tag\n",
    "    if tag.name == \"p\":\n",
    "        # use text for fetch the content inside p tag\n",
    "        paragraphs.append(tag.text)\n",
    "\n",
    "    # For Image use img tag\n",
    "    elif tag.name == \"img\":\n",
    "        # Add url and Image source URL\n",
    "        images.append(url + tag[\"src\"])\n",
    "\n",
    "    # For Anchor use a tag\n",
    "    elif tag.name == \"a\":\n",
    "        # convert into string and then check href\n",
    "        # available in tag or not\n",
    "        if \"href\" in str(tag):\n",
    "            # In href, there might be possible url is not there\n",
    "            # if url is not there\n",
    "            if \"https://en.wikipedia.org/w/\" not in str(tag[\"href\"]):\n",
    "                link.append(url + tag[\"href\"])\n",
    "            else:\n",
    "                link.append(tag[\"href\"])\n",
    "\n",
    "    # Similarly check for heading\n",
    "    # Six types of heading are there (H1, H2, H3, H4, H5, H6)\n",
    "    # check each ta g and fetch text\n",
    "    elif \"h\" in tag.name:\n",
    "        if \"h1\" == tag.name:\n",
    "            heading.append(tag.text)\n",
    "        elif \"h2\" == tag.name:\n",
    "            heading.append(tag.text)\n",
    "        elif \"h3\" == tag.name:\n",
    "            heading.append(tag.text)\n",
    "        elif \"h4\" == tag.name:\n",
    "            heading.append(tag.text)\n",
    "        elif \"h5\" == tag.name:\n",
    "            heading.append(tag.text)\n",
    "        else:\n",
    "            heading.append(tag.text)\n",
    "\n",
    "    # Remain content will store here\n",
    "    else:\n",
    "        remaining_content.append(tag.text)\n",
    "\n",
    "# print(paragraphs, images, link, heading, remaining_content)\n",
    "\n",
    "for l in link:\n",
    "    if \"Daftar_tokoh_agama_Indonesia/wiki/\" in l:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in link:\n",
    "    if \"Tokoh_\" in l:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tii = wikipedia.page(title=\"Amien Rais\")\n",
    "\n",
    "tii.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
